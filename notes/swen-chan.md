---
timezone: UTC+8
---

# Siwei Chen

**GitHub ID:** swen-chan

**Telegram:** 

## Self-introduction

Web3 实习计划 2025 冬季实习生

## Notes

<!-- Content_START -->
# 2026-01-20
<!-- DAILY_CHECKIN_2026-01-20_START -->
**eth最小单位wei的来源**：

1998 年，华裔科学家戴伟（Wei Dai）便提出了匿名分布式电子加密货币 B-Money，中本聪的比特币白皮书参考文献中第一篇就是戴伟（Wei Dai）的文章

账户抽象（AA） 即通过ERC-4337 标准，让以太坊账户具备智能合约的灵活性，简化原有的EOA和CA分治模式。用户无需持有 ETH 即可进行交易，也可以把支付交易费用的功能授权给第三方，支持社交恢复、批量操作等高级功能，极大拓展个人账户。

模块化区块链的概念：

-   **结算层**：最终性和争议解决（Ethereum L1）
    
-   **数据可用性层**：数据存储和检索（Celestia、EigenDA、Ethereum Blob）
    
-   **执行层**：交易处理和状态转换（Optimism、Arbitrum等L2）
    
-   **共识层**：区块排序和最终确定（Ethereum PoS）
    

**记录一下web3岗位的技术栈**

前端：react/vue/viem（以前是ethers.js, web3.js)/typescript/next.js，基本的html/css/js（es6+)就不说了

后端：node.js/go/python; viem/web3.js/ethers.js; RESTful API/GraphQL; MySQL/PostgreSQL; Docker/Kubernetes，熟悉消息队列（如rabbitMQ、Kafka）

智能合约工程师：solidity/remix/foundry/hardhat/phalcon/tenderly/yul

个人角度看，前端和数据分析可能是更适合我当下的。但也不急着定位，我想针对落地多学习，解决问题为主，吸收前沿信息，不局限于某个技术框架。

**区块链开发的基础知识：**

1.前端。与传统 Web 应用不同，DApp 前端不会直接连接区块链网络，而是通过 钱包注入的 Provider 或第三方 RPC 节点 与区块链交互：

（1）通过 RPC 节点对 智能合约发起只读调用（如 eth\_call），获取合约状态、事件日志等链上数据

（2）对需要修改状态的操作，由前端构造对 智能合约的交易调用，交由钱包完成签名后，再通过 RPC 节点广播到区块链网络并最终上链执行

2.智能合约。智能合约是 Dapp 的核心，它定义了应用的**业务逻辑**，并部署在区块链上。

3.数据检索器（indexer）。

（1）智能合约通常以 Event 形式释放日志事件，比如释放代表 NFT 转移的 Transfer 事件，数据检索器会检索这些数据并将其写入到 PostgreSQL 等传统数据库中

（2）Dapp 在前端进行数据展示时需要检索器内的数据。一个简单的示例是某 NFT 项目需要展示用户持有的所有 NFT，但是 NFT 合约并不会提供通过输入地址参数返回该地址下的所有 NFT 的函数，此时我们可以运行数据检索器将 Transfer 事件读取后写入传统数据库内，前端可以在传统数据库内检索用户持有的 NFT 数据

4.区块链和去中心化存储（Blockchain & Decentralized Storage）

（1）区块链用于存储智能合约的状态数据及交易记录。去中心化存储如 **IPFS**（InterPlanetary File System）或 **Arweave**，用于存储大规模的非结构化数据（如图片、文档等），确保数据不易丢失和篡改。

（2）通过使用去中心化存储，Dapp 确保所有数据在多个节点上备份，保证数据的持久性和去中心化特性。

**Dapp 部署具体步骤**包括：

-   **部署智能合约**：推荐使用 **Hardhat** 或 **Foundry**（现代化开发工具）将智能合约部署到测试网（如 **Sepolia**、**Holesky**）或主网。
    
-   **前端部署**：将前端应用部署到去中心化平台（如 **IPFS**）或传统的 Web 服务（如Vercel）。
    
-   **发布和维护**：将 Dapp 上线，进行用户反馈收集，定期更新合约和前端，修复潜在问题。
    

对了，记录一下**拉取github或下载的时候（需要连接github）的网络问题**。

一般是代理没走命令行。

首先可以打开TUN工具

还不行的话，需要手动调一下端口：export http\_proxy="[http://127.0.0.1:7890”（端口号取决于vpn）](http://127.0.0.1:7890%E2%80%9D%EF%BC%88%E7%AB%AF%E5%8F%A3%E5%8F%B7%E5%8F%96%E5%86%B3%E4%BA%8Evpn%EF%BC%89)  
然后再进行操作

备注：env | grep -i proxy 可以check代理端口

今天开始学智能合约啦！装好了foundry以及以下几个工具

-   forge: 帮助构建、测试、调试、部署和验证智能合约
    
-   anvil: 本地开发节点，完全兼容以太坊 JSON-RPC 规范
    
-   cast: 命令行工具，用于与链上应用交互
    
-   chisel：快速、实用且强大的REPL（read，eval，print，loop）
    

发现这几个工具的名字也很有意思。forge，是锻造的意思，相当于炼铁的过程；anvil是铁砧的意思，也就是用来放锻造物的平面块；cast是投掷的意思，很好理解了，就是炼出来的铁用上了！扔到链上去！；chisel则是凿的意思，意味着可以最简单的方式进行工作

foundry的文档要记一下，方便随时查阅命令：

[https://github.com/foundry-rs/foundry?utm\_source=chatgpt.com](https://github.com/foundry-rs/foundry?utm_source=chatgpt.com)

小知识点：

1.Sudoswap将AMM模型应用到NFT交易，创建NFT流动性池，是Uniswap在NFT领域的对标产品。

2.经常说的哈希率（hashrate）就是“算力”，指整个btc网络所有矿工的总计算能力，即每秒能执行哈希运算（本质是一份“解决数学难题”）的次数

3.Genesis Timestamp 的单位是 **Unix 时间戳（POSIX time）**，也就是 **从 1970-01-01 00:00:00 UTC 起算的秒数（seconds）**
<!-- DAILY_CHECKIN_2026-01-20_END -->

# 2026-01-19
<!-- DAILY_CHECKIN_2026-01-19_START -->


今天本来想开始技术向的学习的，毕竟之前也没接触过solidity，结果到现在（22:40）仍然没法开始……

因为刚才发现了学习手册的一个错误，准备当下就修改提交PR。所以我先来把总结写一下，免得一不小心就过0点了哈哈

首先，今天有好几个同学反映连接钱包的问题，有一个wachi老师第一时间@了我。我还挺享受这种承担责任的感觉的哈哈。anyway，也发现了有一个小小的可以提高的用户体验。就是点击connect wallet之后如果取消或者没连接或者连接了，按钮上都会显示connect……其实会容易造成误解。改天我把这个问题也修复一下。

另外，我发现myfirstzknote的钱包连接也是老框架，也是直接选第一个eth钱包连接……我看看过几天这个merge没什么问题之后，我就去把那个项目也修复一下吧。

其次，昨天因为写代码落下的**ERC7962**，也在下午补了补课。

我个人的理解是，ERC7962有点像是在给个体，或者说链上的EOA（或许以后CA也可以）增加一个L2。但这个L2不像区块链的L2向下拓展，而是向上拓展以连接区块链。但是总有些人更想要方便和快捷，毕竟ERC7962的单次私钥验证现实交互中还是麻烦的，所以可能会有些人不想要“L2”。感觉未来趋势还是要兼容ERC7962和ERC721/20。

比如通过一个规范的封装器/适配器（KeyHash20/721 ↔ ERC-20/721），以便 ERC-7962 资产无需重写核心协议即可重用现有的 DEX/借贷/质押基础设施。但这样一来，标准化封装器接口/事件如何处理碎片化的问题？

除了封装器之外，对于受控委托（范围限定、时间/金额限制、可撤销的会话授权），是否存在推荐的“审批替代方案”，既能保留一次性密钥/轮换的目标，又能实现？

对于频繁使用 DeFi 的用户而言，与当前的审批/授权工作流程相比，要求使用一次性密钥和显式的每次操作签名（加上密钥轮换/变更管理）可能过于繁琐。

对于不同用户的倾向，是否可以设想在 ERC-7962 之上构建一个“实用的 UX 层”，例如，有范围的会话委托（时间/金额/合约限制）、将多个意图批量处理为单个签名/交易，还是期望高频用户主要依赖 ERC-20/721 的封装来实现可组合性？

这些都是亟待解决的问题，我post到了ethereum magicians和X上了，希望能有一些讨论。

最后是一些零散的学习笔记：

**学习了UNISWAP的恒定乘积公式**，即**x \* y = k：**

k是一个常数，因此，随着x或y的变化，会相互呈现反比影响，自动计算价格。

有了恒定乘积公式，可以不再依赖人工设置或市场波动，用数学/程序的方式实现了去中心化。

作为个人，可以资金对存入流动性池，成为LP（liquidity provider），从而收取交易手续费，作为担任LP的收益。

这个公式确实出乎我的意料，但却是是可以排除人为干预的最好方法了。

**ZK投票学习笔记：**

ZK投票流程：generate identitySecret(store locally) -> Compute identityCommitment(join the Merkle tree) -> Generate proof + nullifier(Public: root/electionld; Private: secret/path/vote) -> verify(proof) -> verify(proof) -> check nullfier unused(If valid, tally and mark nullifier used)
<!-- DAILY_CHECKIN_2026-01-19_END -->

# 2026-01-18
<!-- DAILY_CHECKIN_2026-01-18_START -->



今天主要是提交了个pr，链接：[https://github.com/lxdao-official/myfirstnft-frontend/pull/20](https://github.com/lxdao-official/myfirstnft-frontend/pull/20)  
关于myfirstnft网页的这个问题，我第一天也遇到了，但是当时没多想，觉得完成任务就行了。

但后来看到和我一样的同学越来越多，我就萌生了修复这个问题的想法，直到今天在群里又看到有人提到这个错误，我就动手了。

很久没有提交pr，折腾了一下午环境，算是敲了一晚上代码，赶在24点之前提交了。

具体说，PR 修复的问题是，即在用户选择连接 MetaMask 时，实际上弹出了其他钱包。这是由于 Web3Modal v1 中的 `injected` 提供商默认选择了最近注入的 `ethereum` 钱包。通过将 MetaMask 作为自定义提供商选项添加，我们确保了正确的 MetaMask 钱包被选中，并显示在 Web3Modal 界面中。

晚上敲代码都忘了看直播课……最后才想起来打了个卡。算了没事，上次忘记打卡后就不追求排名了
<!-- DAILY_CHECKIN_2026-01-18_END -->

# 2026-01-17
<!-- DAILY_CHECKIN_2026-01-17_START -->




### 1.今天准备了LXDAO 新成员发言，但没轮到哈哈哈。那就下周再说吧

### 2.然后记录一下今天和wachi老师沟通学到的精华（他原话）：

**我觉得Web3需要的最核心的技能是在这里，在知道技术边界的前提下，做出好的设计。最后再vibe coding让AI五分钟把Solidity写出来哈哈哈**

我其实作为一个转行人，其实是对技术有焦虑的。倒也不是技术本身的焦虑，任何语言、框架、项目，我觉得真的上手了也就那样，熟能生巧。问题在于，一旦缺失了企业级的经历，就无法再获得企业级的机会，这是个死循环

### **3.思考了一个问题：关于“没有中心化机构/税收”，公共基础设施谁来维护？如果有税收又如何分配“**（这也是之前bruce老师留下的思考题）：

这是经济学上典型的公共品搭便车问题。

在web3的可行机制探讨：协议内生资金（发行/区块奖励/手续费/MEV）；基金会/生态资助/DAO Grant；二次方资助/追溯性公共品资助；企业赞助+商业化反哺

税收分配：DAO机制公开决定比例和方向，规则上链，尽量与效果挂钩

### **4.今天和wachi老师聊了下UCP与x402集成的可能**

首先介绍一下UCP和x402

**UCP（Universal Commerce Protocol）是一个面向“Agentic Commerce（代理式商业）”的开放协议，目标是让 AI Agent 能用统一语言完成从“发现商品/服务→发起结账→完成支付→订单生命周期管理”的全链路交互**。也就是说，agent可以把“登录、选规格、填地址、付款、查物流、退货”这些流程和接口全打通，一键复用。

在支付层面，UCP 采用 **“Payment Handler（支付处理器/处理方式）”的模块化机制**：

-   支付凭证/支付能力提供方（Payment Credential Provider）发布“处理器规范（Handler Definition）”，包含 JSON Schema 等“蓝图”；
    
-   商家（Business）选择某个 handler，并在 Checkout 响应里填入自己的配置（例如 merchant id、公钥、环境等）；
    
-   平台（Platform）读取商家配置，按 handler 规范去执行“支付凭证获取/处理流程”。
    

**x402**是一个“把支付嵌入 HTTP 请求”的开放标准，本意为复活 HTTP 里长期“预留未广泛使用”的 **402 Payment Required**

流程：

1.资源服务器（API/网页/服务）在未收到付款时返回 **402**，并给出“需要如何支付”的要求；

2.客户端（可为 AI agent）按要求签名/构造支付载荷，再重试请求；

3.服务器可本地验证或通过 **facilitator** 去验证与结算。

图示如下：

我认为两者集成 **在 API/数字服务/Agent 工具调用（按次计费）场景可行且契合**，似乎pieverse也在做这个事情了。

\*\*集成方式：\*\*把x402 封装成 UCP 的一个 Payment Handler

按UCP guide文档定义好：

handler declaration(name, version, spec, config\_schema, instrument\_schemas)

config\_schema.json(env, facilitator, payee/chain/asset等）

instrument shcema(requirement id, amount, asset, order id等）

credential schema(sign, nonce, challenge, receipt）

**测试：**

可重复执行的状态机：

1.  客户端request → 服务器返回402 challenge
    
2.  客户端选择requirement → 构造 payload → 签名
    
3.  重试request → 服务端verify/settle
    
4.  返回 success + receipt/response
    

但和wachi老师交流后发现，我可能忽视了产品落地的复杂性。

目前“Agent 支付/链上支付”的真实可落地能力，行业普遍只做到“单笔付款（一次性转账）”这一层。要实现upto和流支付，目前还没有落地的方案。这方面，先保持关注吧。

### **5.因为聊到了polymarket，也就顺便了解了一下UMA(Universal Market Access)**

UMA是一个去中心化金融协议，允许用户创建和交易追踪任何资产价格的合成资产。可以充当乐观预言机，通过代币持有者验证数据，保障链上数据准确性，支持Web3市场。在polymarket的场景下，当出现结果challenge的情况，就需要UMA tokenholders去投票裁决。

### **6.关于polymarket的optimistic oracle+社区投票解决challenge机制**

wachi老师问了我两个问题：

（1） 为什么社区有动力投票呢？

（2） 一个market resolved之后，仓位就已经结算了。如果dispute成功，整个refund的流程是什么样的，资金从哪里出？

回答：

（1）这个问题我其实也在思考。一个退货的dispute，怎么能号召社区来投票呢？我们现实在小区中，修个电梯让大家达成一致都能拖个一年半载的，怎么能保证社区有动力投票。我想从经济和人性的角度，可能还是要从激励出发。

首先我check了polymarket的UMA文档

发现这确实也是个复杂的问题，既要给诚实的参与者奖励，也要惩罚不诚实，我还看到提高经济成本等做法

感觉这个设计就有点像我们之前讨论的，大户本身利益也是绑定在网络上的，这本身就是最好的经济约束

（2）refund的流程是：polymarket每个结果都有2小时的challenge period；2小时内有dispute的话，请求送到UMA DVM座位backstop，由tokenholders投票裁决；然后才会把UMA的结果写入“最终不可逆结算”。

dispute过程有一个bond机制，proposer和challenger各自押上bond，用结果再分配，这样就解决了资金的问题

我的思考是：虽然两个问题已经解决方法。但

（1）UMA token holders仍然可能受“外部激励”导致中心化投票的结果；

（2）一个模糊的问题更可能引起论战，所以如何提高问题本身措辞的精准是更“第一性”和更有效率的问题。如果为了解决模糊问题而搞一堆治理解决方案，反而本末倒置；

（3）有可能出现即便错误结果，但无人挑战的情况，尤其是冷门盘，小资金参与、低活跃时间的情况下

wachi老师说他觉得对于pm这种，一个市场毕竟有多方参与，大家会上心一点。但如果只是一笔交易，参与者只有买卖双方，这个机制感觉也要改

我的看法是：单笔交易的话，感觉可以引入“竞选纠错者”，给点经济激励，允许套利者参与纠错、裁决；或者就是有个整体的仲裁池，可以给这些“尾部”交易出现dispute的情况兜底。
<!-- DAILY_CHECKIN_2026-01-17_END -->

# 2026-01-16
<!-- DAILY_CHECKIN_2026-01-16_START -->






打卡的同时，分享会仍在进行中。刚才有事送朋友下楼去车站，第7个之后的同学都没有听到，现在听到了最后两个同学。

我今天在晚上的分享会进行了学习分享。

其实还是蛮紧张的，虽然各种场合也发言不少了，但还是有实感的紧张。

本来想要分享Tomasz说的基于ERC-8004的创业公司可能已经开始发展，与昨天rick老师分享的spoonOS项目结合起来。但却在分享的时候忘掉了，挺可惜的。

but anyway，很开心，也很感谢平台的机会，真心希望我的分享有帮助到大家。

关于很多同学分享的学习工具，我多多少少在以前都尝试过，什么“工作流”、“流程化”，到最后往往因为不可持续性而放弃。现在的我更关注“可持续性”和学习本身。如果维护形式需要花的精力已经影响到了学习本身，我是毫不犹豫会放弃的。目前我的笔记系统也很简单，随记和简单的笔记，就直接放在apple notes上（包括本次项目的笔记），长篇的笔记，比如我个人的总结之类，我会放在notion，未来可能转移到本地。总之，最方便的笔记方式才是我更喜欢的～

看到有同学分享uniswap和solidity，我还是有点兴奋的哈哈。准备开搞了！

然后分享一下今天的学习笔记：

**学习一下锁的机制**

首先，锁存在的意义呢，就是为了避免共享资源之间的互斥访问。通过“加锁-访问-解锁”的顺序，实现共享资源的有序访问。这就像图书馆的一个座位一样，一次只能坐一个同学。每一个同学想坐的话，需要先申请，相当于“加锁”，然后就坐学习相当于“访问”，走的时候状态转化，相当于“解锁”。

常见类型有互斥锁 (Mutex)：基本锁，保证一次只有一个线程能访问，常用于保护临界区；读写锁 (Read-Write Lock)：允许多个读线程同时访问，但写线程仍然是独占，提高了读多写少的场景效率；信号量 (Semaphore)：比互斥锁更通用，控制同时访问特定资源的线程数量。自旋锁 (Spin Lock)：尝试获取锁失败时，线程不休眠而是原地循环尝试（自旋），适用于锁竞争不激烈的情况。

注意，死锁 (Deadlock)是指两个或多个线程互相等待对方释放资源而僵持不下的状态。

其实，总的来看，锁就是为了权衡并发性和资源保护而创造的工具。

**学习一下zk-proof（ZKP）和zkEVMs：**

首先，zk也就是zero-knowledge，其意义在其字面，即允许一方在不暴露任何信息的情况下向另一方证明拥有特定信息。zk算法分为zk-STARKs和zk-SNARKs。

而zk和EVMs的结合，就是把“EVM 执行过程”变成可验证的代数约束，然后用zk算法证明“这些约束被满足”
<!-- DAILY_CHECKIN_2026-01-16_END -->

# 2026-01-15
<!-- DAILY_CHECKIN_2026-01-15_START -->








1.15

今天重新拾起之前只做完mvp的agent项目，太久没看有点忘了，先把项目顺了一下。温习了以下知识点：

1.在使用OpenAI的chat.completions接口时，可用的参数包括：

temperature:温度参数，控制生成文本的随机性

max\_tokens: 限制生成最大token数量

top\_p(nucleus sampling):一般在0.8-0.95间；正比于文本的多样性和创造性，反比于文本的可预测性和相关；本质是“从概率从高到低累计达到p的那一组词中随机选择下一个词“）

top\_k(Top-k sampling): 只从模型认为最可能的”k“个词中选择下一个词。正比于文本多样性

n：生成的回复数量，会在response.choices中返回

传递给model的messages里面，system传递系统指令，user传递具体任务要求，assistant是历史助手输出，承接上下文

注意：openai官方文档建议不要同时调整temperature和top\_p，因为这是一对替代参数，服务同样的目的

**复习了下python中的with语句**

有的时候，总是会面对着代码发呆，即便是以前自己写出来的……不知道是不是只有自己有这个症状。比如今天又对着with发呆了……

好吧，按官方一点的话说，with是一种上下文管理协议。

通俗点看，with就相当于file先open再close，只是更便捷，也更容易进行异常处理。

所以with其实是open 和close，再结合try&except&finally的包装体。

好了，眼前的with又变清秀了……

**今天晚上的ai agent课**超级爱，完全贴合我的兴趣。我准备周末看看spoonOS的源代码，看看可不可以做点有意思的事情。

至少我现在能想到的优化有：声誉体系的优化（评分矩阵，以及沟通agent与developer之间的评分），甚至是对ERC8004的补充；声誉系统防刷（其实我感觉这个如果是建立在普遍的trust score系统上，会更加健壮，就像我看vitalik采访说的其实现在core developer也在聚焦这个事情）

然后就是理解EIP1559对gas的改革，wachi老师给的这个网站非常好，一动手就懂：[https://aistudio.google.com/apps/drive/1GTbHPGD\_x\_rOSzEPKFI7T\_S8Nj8AKVGM?fullscreenApplet=true&showPreview=true&showAssistant=true](https://aistudio.google.com/apps/drive/1GTbHPGD_x_rOSzEPKFI7T_S8Nj8AKVGM?fullscreenApplet=true&showPreview=true&showAssistant=true)

留一下，以后我也发给有需要的人

今天也发了一条X分享学习！今天在社群也超活跃！发了测试币给拿不到币的同学，也把直播分享给了一个对web3感兴趣的朋友。
<!-- DAILY_CHECKIN_2026-01-15_END -->

# 2026-01-14
<!-- DAILY_CHECKIN_2026-01-14_START -->









服了 现在是14号的0:51， 13号的打卡超了40分钟，这么快就用了一次请假

在具体的笔记之前，我也在这两天做了很多改变，比如身为超级大i人，今天也在co-learning中进行了分享；比如作为社交能量较低的人，也开始在X分享学习；努力开始高能量地展示和社交，寻找web3的工作机会；这两天一直学习腰很酸，今天晚上出去跑了步，感觉神清气爽；比如今天主动联系LXDAO申请加入；

很感谢这个活动，就像我在X中写的，我是一个如果自己待着会越来越熵减、直到坍塌的人，从开营感觉到社区的活力开始，我感觉自己进入了新的模式，也是一种很熟悉的沉浸模式。

我正享受其中，希望这个时间可以更长一些。

先把13号的笔记补一下：  
**2026.1.13**

观看ETHPanda对ETH基金会新任联合执行董事Hsiao wei Wang的采访视频：[https://x.com/ETHPanda\_Org/status/1924660825727582238](https://x.com/ETHPanda_Org/status/1924660825727582238)

感想：

[1.wang](http://1.wang)本人是2017年开始在以太坊基金会做研究员，说明华人在EF也是有发展路径的，web3的机会仍然很多

2.任何人都可以发起EIP，通过会议获得更多支持后可以参加ACD会议去与核心开发讨论，后续列入候选并测试

3.可能爆发的方向：identity，socialFi，farcaster的小程序，RWA

4.社区中不要追求ownership，有事情就去做

5.哪些生态和社区工作缺少推动：带进更多新学员（学生社群），感觉这就是ETHPanda和LXDAO在做的事情

6.研究员时期专注consensus layer的specification，现在更多精力在management上

7.ETH基金会在管理层之下分为三个事业集群：operations，Eco Dev,PR&D

8.EF正在通过lending，stake和RWA等方式拓宽收入渠道

9.卖币是必须用法币来维持基金会运作（近300人）

**今天系统地了解一下“以 rollup 为中心，通过 blobs 的“数据分片化/数据可用性扩展”实现“是如何在ETH网络运行的”：**

这个事情过去是通过shard chain将“执行”（execution）拆分为多条链并行跑的。现在的方法则是：不分片“执行”，而是分片“数据”，具体是：blobs+分布式数据采样

感觉可以把一份数据上传到ETH网络的过程比喻成坐飞机的过程。客舱就是L1，行李舱是L2。为了减少L1的压力，所以把大件行李都通过单独的L2存放，L1只保留DA/blobs通道连接L2。同时，L2有单独的blob gas定价，可比作托运行李费（廉航），而行李费用肯定是远低于机票的，所以可以大大节省L1的成本。

把“执行（execution）”的规模化主要交给 Rollup，把 L1（以太坊主网）优化成更强的“结算 + 数据可用性（DA）”底座；而 blobs 是 L1 专门为 Rollup 发布数据而提供的一种更便宜、更可扩展的数据通道。

**“以 rollup 为中心”到底是什么意思？**

Rollup（无论是 Optimistic 还是 ZK）都遵循同一核心模式：

1.  在 L2 上执行大量交易（把计算搬到链下/二层）
    
2.  定期把一个批次（batch）的结果“锚定”到 L1：
    
    -   提交 状态承诺/状态根（以及必要的元数据）到 L1 合约
        
    -   同时把足够的数据发布到 L1，使任何人都能在需要时重放/验证 L2 的状态演进（这就是 DA 需求）
        

这样做的意义是：L2 的执行吞吐可以很高，而 L1 只需承担“最终仲裁者”的角色（谁对谁错、能否挑战、能否提现等都以 L1 规则为准）。

**为什么扩容瓶颈会落到“数据可用性（DA）”上？**

即使交易在 L2 执行，L2 仍必须把“交易数据（或足以重放的压缩数据）”公开出来，否则会出现一个致命问题：

-   Sequencer 只公布“新状态根”，但不公布交易数据
    
-   外部观察者无法验证或重放
    
-   用户也可能无法独立退出（因为缺乏证明所需的数据）
    

所以对 Rollup 来说，最贵、最难扩展的往往不是计算，而是“把数据安全地发布到 L1”。历史上这部分多靠把数据塞进 L1 的 calldata，但它昂贵且长期存储压力大。

**blobs（EIP-4844）解决的就是“给 Rollup 一条更便宜的数据发布通道”**

EIP-4844 引入一种新交易类型（常被称为 blob-carrying transactions）：

-   交易可以“携带”一个或多个 blob 数据块
    
-   EVM 不能直接读取 blob 内容，只能读取其承诺/哈希（commitment）等摘要信息
    
-   blob 数据会在网络中临时保存，并在大约18 天后被修剪（pruned），以控制长期磁盘压力
    
-   blob 数据主要由共识层（beacon 节点）负责保存与传播，而不是执行层客户端
    

为什么它会显著降低 L2 成本

关键在于：blobs 有独立的“费用市场”，执行 gas 和 blob gas 分别定价（常被称为 two-dimensional fee market）。这让 Rollup 发布大量数据时，不必挤占/支付同样昂贵的执行资源价格 。

**当前danksharding（EIP-4844）的进度**

第一步：Proto-danksharding（EIP-4844）——先把 blobs 跑起来

-   引入 blob 交易 + 独立费用市场
    
-   先把 Rollup 的 DA 成本显著降下来
    
-   但还没有实现完整的数据可用性采样（DAS）（即**节点仍倾向于下载/传播完整 blob，而非只采样**）
    

当前（至少在 Dencun 引入 EIP-4844 后的一段时期）常见参数描述是：每个以太坊区块目标 3 个 blobs、最多 6 个 blobs，单个 blob 约 ~128KB。  
并且这些参数是可在后续升级中上调的；一些资料提到后续升级会提高目标/上限（例如从 3/6 提到更高），实现更大 DA 吞吐。

第二步：Full danksharding——把 DA 容量做大且保持去中心化

目标：把 blob 容量提高很多，同时让节点不需要“全量下载全部数据”也能确信数据可用。**做法核心是数据可用性采样（DAS）：节点随机抽样验证数据可用性，从而在不牺牲去中心化的前提下扩展 DA**。

**一个典型的“Rollup 发布批次”的流程**：

1.  L2 Sequencer 收集交易，在 L2 执行并得到新状态
    
2.  把本批次的 **交易数据/状态差分数据**打包成 blob（大量数据放 blob）
    
3.  向 L1 发一笔 EIP-4844 交易：
    
    -   **blob 里**放“可重放数据”
        
    -   交易本体（EVM 可见部分）放必要的承诺/引用与 L2 状态承诺（供 L1 合约记录与约束）
        
4.  网络在一段时间内保存 blob 数据（便于挑战者/证明者下载验证），随后修剪
    
5.  Rollup 的安全性仍由其证明机制（fraud/validity）+ L1 结算规则决定；blobs 主要降低 DA 成本并提升 DA 吞吐
    

**web3运行原理笔记**

1.钱包负责组装交易内容,使用私钥进行签名,然后广播到区块链网络，nonce通过递增达到不重复的效果。

2.数字签名流程:使用私钥对交易信息进行签名,任何人都可以验证签名是否来自该私钥,但无法伪造签名；接收方通过原始消息、声称发送的地址和签名三个信息,使用密码学算法反推签署者身份进行验证

3.交易周期：钱包签名→通过RPC发送到网络→排队→验证者(validator)和构建者(builder)挑选→组装成区块→通过共识打包→加入区块链

4.关于RPC的中心化风险：钱包不直接连接区块链,而是通过RPC(API)连接到节点集群；RPC是中心化风险点,如果RPC服务商拒绝转发或拦截签名,交易无法上链；目前是通过多个RPC服务器可选来降低单点故障风险

5.智能合约的本质：调用合约时,代码在虚拟机临时运行环境中执行,结果写入区块链；Code is law，规则可验证,任何人都可以检查规则和执行历史,降低信任成本；通过交换合约实现NFT和代币的无中介交换,消除传统世界中的律师、法院等中间环节；

# **1.14 笔记**

观看ETHPanda对ETH基金会联合执行董事Tomasz的采访视频：[https://x.com/ETHPanda\_Org/status/2005459351524479257](https://x.com/ETHPanda_Org/status/2005459351524479257)

感想：

1.经历：Tomasz是ETH网络主要客户端nethermind的创始人，此前做了10年+的银行基础设施开发。虽然不在EF，但nethermind一直都是ETH网络的重要贡献者

2.最具挑战性的工作可能是用户体验部分，因为很难量化，也很难定义，更难让大家都同意同一个定义

3.L2互操作性的一个问题是供应商之间的利益冲突和商业冲，即便工程师们并不排斥互相沟通

4.当AI需要truth的时候，就是需要web3的时候。web2的世界太虚假了，也不存在“真实验证”。web3提供的隐私和数据可靠性会让AI受益。

5.x402和ERC-8004都基于MCP和A2A之上。x402是支付请求；ERC-8004用于agent使用区块链的信任（trustless），基于A2A

6.开发者正在养成和AI交流的习惯；而LLM越强大，LLM训练的数据和过程将会对开发者的思维影响越大

7.chaoschain在做的事情：agents之间如何协作做决定、设置reward function，反馈结果；这个过程有点像proof of work；

8.agent可以参与EIP的制定过程，参与dev会议并讨论，甚至开视频。（这也很自然，但也很超现实

9.EF有dAI team，由David Crapis领导，也是发布ERC-8004的团队。现在或许已经有初创团队在基于ERC-8004制作产品

10.很大的感触是，Tomasz被问到如何保持精力时，他说自己只是穿梭在不同时区之间，并没有schedule和精确的作息，因为很忙的时候对自己这么苛刻其实没必要。深以为然，我就曾经对自己的作息过于苛刻，反而造成焦虑，不仅更难保持规律，反而影响正常工作。前两天问wachi老师这个问题，他的回答也是“干累了睡”，我豁然开朗。找到组织了哈哈

合规和安全的晚课，我基本是当作背景听完的，收益颇多。但我其实没有大家的那种震撼，由于我的经历原因，我对大陆的权力结构比较熟悉，也长期关注一些边缘群体和事件。虽然我不是法律行业，但邓律的解答基本都在我的意料之内，甚至比我想象的要“文明”多了。

来共学之前，我也算是在币圈野蛮独自存活了两三年，所以很多东西自己都有所了解或研究，只是一直没找到组织和大佬来系统带领。前两天，看到有人上麦或是评论区的一些留言，我的直觉就能告诉我此人适不适合web3，或者是抱着怎样的想法来web3的。我想不方便在会议里说、却很重要的一点是，区块链的诞生就是对gov和宏大叙事天然不信任的产物，btc的诞生则是对主权金融叙事不信任的产物。btc是区块链在金融的显化，其本质是实现个人主权和自治。如果没有这样的信仰，我想只会是web3的过客的。在一点上，我想我比大多数学员要更坚定。
<!-- DAILY_CHECKIN_2026-01-14_END -->

# 2026-01-12
<!-- DAILY_CHECKIN_2026-01-12_START -->











**2026.1.12**

早上看完了ETHPanda对vatalik的采访视频:[https://x.com/ETHPanda\_Org/status/1846109488442757627](https://x.com/ETHPanda_Org/status/1846109488442757627)

**感想：**

1.  身份认证体系会革新，graph代替中心化评价体系，数据源更大，更公平；trust score可能是绝对的、也可能是相对的，每个人的identity也可能是多维度的
    
2.  未来web3项目的首要问题是：钱从哪里来，如何分配，如何衡量贡献
    
3.  完全的国际主义是理想主义，现实中有些人即便在web3也可能不会选择成为国际主义，社会会更加convergence。
    
4.  同样的，在社会制度层面，类似资本主义和社会主义的争论也变得没有必要，因为在不同的具体场景中会mix
    
5.  如何强制商业公司给开源协议分配收入？
    
6.  当前eth有5个客户端，如果未来有100个客户端，可能会有很多hard fork。感觉这个可以引申到去中心化的极限问题
    
7.  在incentives角度，未来判断一段代码的归属权(ownerships)比较难
    
8.  以太坊基金会/开发团队，正在以一种更加online的方式展开
    
9.  如果要在火星上建设以太坊节点，目前最可行的方法是做火星layer2
    
10.  obfuscation可以做到在程序中转交私钥的一部分权力，而不泄露私钥；但无法阻止整个程序被复制，或许可以用量子方法解决，one-time signatures；未来obfuscation和量子结合可以很强大
     

**下午co-learning的笔记**

1.foundary可以提供智能合约在正式部署前的开发框架，用于测试和模拟、部署依赖和多步脚本，进行管理。hardhat则是比较老的同类平台（wachi）

2.找工作需要聚焦在前后端开发+solidity智能合约部署上，尽快搭建MVP，以结果为导向。

**关于ETH生态层次：**

  
**应用层**决定用户价值与产品形态

**中间件**决定可用性与可组合性（钱包与账户体系、预言机、索引与数据服务、身份&权限&合规组件、MEV）

**L2/桥**决定扩容与资产流动的“地理版图”（Sequencer、Batcher/Proposer）

**资产层**决定金融基座与流动性分配（ETH资产、GAS、证明系统、桥与跨域消息）

**节点/网络**决定系统可达性与抗审查能力

**协议层（分为共识协议与执行协议及两者接口）**决定最终安全性与规则边界

每个ETH网络的节点会运行客户端，连接到整个ETH网络。每个客户端包括一个共识协议进程和一个执行协议进程，以及两者沟通的engine API通信

**出块协作流程**：出块协作流程也给了很清晰的描述：共识层知道轮到自己出块后，会通过本地 RPC 调用执行客户端创建区块；执行层从自己的 mempool 取交易、执行并生成区块相关结果。
<!-- DAILY_CHECKIN_2026-01-12_END -->
<!-- Content_END -->
